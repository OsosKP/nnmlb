{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../core/output/batters.csv')\n",
    "indexer = df.reset_index()[['index', 'retroID']].to_dict()['retroID']\n",
    "y = df['Batting'].values\n",
    "to_drop = ['debutYear', 'finalYear', 'G', '1B', 'AB', 'RBI', 'wOBA']\n",
    "df.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retroID</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>pos_1B</th>\n",
       "      <th>pos_2B</th>\n",
       "      <th>pos_3B</th>\n",
       "      <th>pos_C</th>\n",
       "      <th>pos_OF</th>\n",
       "      <th>pos_P</th>\n",
       "      <th>pos_SS</th>\n",
       "      <th>...</th>\n",
       "      <th>SO</th>\n",
       "      <th>IBB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>GIDP</th>\n",
       "      <th>NL</th>\n",
       "      <th>wRC+</th>\n",
       "      <th>WAR</th>\n",
       "      <th>Batting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardd001</td>\n",
       "      <td>0.569672</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaroh101</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1383</td>\n",
       "      <td>293</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>121</td>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>136.3</td>\n",
       "      <td>0.350195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aarot101</td>\n",
       "      <td>0.467213</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.157131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aased001</td>\n",
       "      <td>0.467213</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abada001</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.090001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>zupcb001</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.156062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>zupof101</td>\n",
       "      <td>0.434426</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.123425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>zuveg101</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.090088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>zuvep001</td>\n",
       "      <td>0.397541</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.135118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15292</th>\n",
       "      <td>zycht001</td>\n",
       "      <td>0.467213</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        retroID    weight  height  pos_1B  pos_2B  pos_3B  pos_C  pos_OF  \\\n",
       "0      aardd001  0.569672    0.60       0       0       0      0       0   \n",
       "1      aaroh101  0.426230    0.45       0       0       0      0       1   \n",
       "2      aarot101  0.467213    0.60       1       0       0      0       0   \n",
       "3      aased001  0.467213    0.60       0       0       0      0       0   \n",
       "4      abada001  0.442623    0.50       1       0       0      0       0   \n",
       "...         ...       ...     ...     ...     ...     ...    ...     ...   \n",
       "15288  zupcb001  0.590164    0.65       0       0       0      0       1   \n",
       "15289  zupof101  0.434426    0.40       0       0       0      1       0   \n",
       "15290  zuveg101  0.487705    0.65       0       0       0      0       0   \n",
       "15291  zuvep001  0.397541    0.45       0       0       0      0       0   \n",
       "15292  zycht001  0.467213    0.60       0       0       0      0       0   \n",
       "\n",
       "       pos_P  pos_SS  ...    SO  IBB  HBP  SH   SF  GIDP  NL  wRC+    WAR  \\\n",
       "0          1       0  ...     2    0    0   1    0     0   1  -100   -0.1   \n",
       "1          0       0  ...  1383  293   32  21  121   328   1   153  136.3   \n",
       "2          0       0  ...   145    3    0   9    6    36   1    76   -1.7   \n",
       "3          1       0  ...     3    0    0   0    0     0   1  -100   -0.1   \n",
       "4          0       0  ...     5    0    0   0    0     1   1     0   -0.4   \n",
       "...      ...     ...  ...   ...  ...  ...  ..  ...   ...  ..   ...    ...   \n",
       "15288      0       0  ...   137    3    6  20    8    15   0    74   -0.9   \n",
       "15289      0       0  ...     6    0    0   0    0     0   0    37   -0.2   \n",
       "15290      1       0  ...    39    0    0  16    0     3   1     0   -0.3   \n",
       "15291      0       1  ...    50    1    2  18    0     8   1    52   -2.2   \n",
       "15292      1       0  ...     0    0    0   0    0     0   0     0    0.0   \n",
       "\n",
       "        Batting  \n",
       "0      0.000358  \n",
       "1      0.350195  \n",
       "2      0.157131  \n",
       "3      0.000358  \n",
       "4      0.090001  \n",
       "...         ...  \n",
       "15288  0.156062  \n",
       "15289  0.123425  \n",
       "15290  0.090088  \n",
       "15291  0.135118  \n",
       "15292  0.090195  \n",
       "\n",
       "[15293 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building the Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Batting']).values\n",
    "y = df[['retroID', 'Batting']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When we do our train-test split, since it's random in how it splits up the data, we need to keep track of the appropriate keys (retro IDs) for each data point.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_train_keys = np.asarray([x[0] for x in X_train])\n",
    "X_train = np.asarray([x[1:] for x in X_train])\n",
    "X_test_keys = np.asarray([x[0] for x in X_test])\n",
    "X_test = np.asarray([x[1:] for x in X_test])\n",
    "y_train_keys = np.asarray([y[0] for y in y_train])\n",
    "y_train = np.asarray([y[1] for y in y_train])\n",
    "y_test_keys = np.asarray([y[0] for y in y_test])\n",
    "y_test = np.asarray([y[1] for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12234, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor_input(player):\n",
    "    return scaler.transform(player.values.reshape(-1,29))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = df.drop(columns=['retroID', 'Batting'])\n",
    "player_tensor_inputs = tensor.apply(lambda player: to_tensor_input(player), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.5696720000000001, 0.6, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1        [0.42623, 0.45, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "2        [0.467213, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3        [0.467213, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "4        [0.44262299999999993, 0.5, 1.0, 0.0, 0.0, 0.0,...\n",
       "                               ...                        \n",
       "15288    [0.590164, 0.65, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...\n",
       "15289    [0.43442600000000003, 0.4, 0.0, 0.0, 0.0, 1.0,...\n",
       "15290    [0.487705, 0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...\n",
       "15291    [0.397541, 0.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "15292    [0.467213, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "Length: 15293, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_tensor_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = pd.DataFrame(player_tensor_inputs.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.to_csv('../core/tensors/t_batting.csv', index=False, float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "batch_size = 128\n",
    "loss_param = 'mse'\n",
    "optimizer_param = 'adam'\n",
    "stop_monitor = 'val_loss'\n",
    "stop_patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(116, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(232, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(116, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=loss_param, optimizer=optimizer_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(58, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(116, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(58, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=loss_param, optimizer=optimizer_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=stop_monitor, patience=stop_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12234 samples, validate on 3059 samples\n",
      "Epoch 1/400\n",
      "12234/12234 [==============================] - 1s 81us/sample - loss: 0.0398 - val_loss: 0.0242\n",
      "Epoch 2/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0208 - val_loss: 0.0143\n",
      "Epoch 3/400\n",
      "12234/12234 [==============================] - 0s 25us/sample - loss: 0.0132 - val_loss: 0.0091\n",
      "Epoch 4/400\n",
      "12234/12234 [==============================] - 0s 32us/sample - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 5/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 6/400\n",
      "12234/12234 [==============================] - 0s 28us/sample - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 7/400\n",
      "12234/12234 [==============================] - 0s 27us/sample - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 8/400\n",
      "12234/12234 [==============================] - 0s 28us/sample - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 9/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 11/400\n",
      "12234/12234 [==============================] - 0s 27us/sample - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 12/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 13/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 14/400\n",
      "12234/12234 [==============================] - 0s 28us/sample - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 15/400\n",
      "12234/12234 [==============================] - 0s 32us/sample - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 16/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 17/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 19/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/400\n",
      "12234/12234 [==============================] - 1s 59us/sample - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 21/400\n",
      "12234/12234 [==============================] - 1s 54us/sample - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/400\n",
      "12234/12234 [==============================] - 1s 65us/sample - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/400\n",
      "12234/12234 [==============================] - 1s 52us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 24/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 25/400\n",
      "12234/12234 [==============================] - 1s 49us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 26/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 27/400\n",
      "12234/12234 [==============================] - 1s 67us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 28/400\n",
      "12234/12234 [==============================] - 1s 60us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 29/400\n",
      "12234/12234 [==============================] - 1s 66us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 30/400\n",
      "12234/12234 [==============================] - 1s 41us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 31/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 32/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 33/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 34/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 35/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 36/400\n",
      "12234/12234 [==============================] - ETA: 0s - loss: 0.001 - 1s 47us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 37/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 38/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 39/400\n",
      "12234/12234 [==============================] - 1s 53us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 40/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 41/400\n",
      "12234/12234 [==============================] - 1s 59us/sample - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 42/400\n",
      "12234/12234 [==============================] - 1s 53us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 43/400\n",
      "12234/12234 [==============================] - 1s 57us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 44/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 45/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 46/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 47/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 48/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 49/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 50/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 51/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 52/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 53/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 54/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 55/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 56/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 57/400\n",
      "12234/12234 [==============================] - 1s 49us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 58/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 59/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 60/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 61/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 62/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 63/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 64/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 65/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 66/400\n",
      "12234/12234 [==============================] - 0s 41us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 67/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 68/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 69/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 70/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 71/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 72/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 73/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 74/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 75/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 76/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 77/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 78/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 79/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 80/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 81/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 82/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 83/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 84/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 85/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 86/400\n",
      "12234/12234 [==============================] - 1s 41us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 87/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 88/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 89/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 90/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 91/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 92/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 93/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0014 - val_loss: 9.8121e-04\n",
      "Epoch 94/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0014 - val_loss: 9.8427e-04\n",
      "Epoch 95/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 96/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 97/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0014 - val_loss: 9.6748e-04\n",
      "Epoch 98/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 99/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0015 - val_loss: 9.5662e-04\n",
      "Epoch 100/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0015 - val_loss: 9.7917e-04\n",
      "Epoch 101/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0014 - val_loss: 9.5729e-04\n",
      "Epoch 102/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0014 - val_loss: 9.5152e-04\n",
      "Epoch 103/400\n",
      "12234/12234 [==============================] - 1s 53us/sample - loss: 0.0014 - val_loss: 9.3312e-04\n",
      "Epoch 104/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0014 - val_loss: 9.5747e-04\n",
      "Epoch 105/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0014 - val_loss: 9.3879e-04\n",
      "Epoch 106/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0014 - val_loss: 9.7322e-04\n",
      "Epoch 107/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0015 - val_loss: 9.6365e-04\n",
      "Epoch 108/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0014 - val_loss: 9.8918e-04\n",
      "Epoch 109/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 9.3903e-04\n",
      "Epoch 110/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 111/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 9.7432e-04\n",
      "Epoch 112/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0014 - val_loss: 9.6264e-04\n",
      "Epoch 113/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0014 - val_loss: 9.3307e-04\n",
      "Epoch 114/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0014 - val_loss: 9.5770e-04\n",
      "Epoch 115/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 116/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0014 - val_loss: 9.3083e-04\n",
      "Epoch 117/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 9.3811e-04\n",
      "Epoch 118/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0014 - val_loss: 9.0569e-04\n",
      "Epoch 119/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0014 - val_loss: 9.6265e-04\n",
      "Epoch 120/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 9.0330e-04\n",
      "Epoch 121/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 9.2670e-04\n",
      "Epoch 122/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 123/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0014 - val_loss: 9.0224e-04\n",
      "Epoch 124/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0014 - val_loss: 8.9874e-04\n",
      "Epoch 125/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0014 - val_loss: 9.0275e-04\n",
      "Epoch 126/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 127/400\n",
      "12234/12234 [==============================] - 1s 43us/sample - loss: 0.0014 - val_loss: 8.9648e-04\n",
      "Epoch 128/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0013 - val_loss: 8.9572e-04\n",
      "Epoch 129/400\n",
      "12234/12234 [==============================] - 0s 41us/sample - loss: 0.0014 - val_loss: 9.9402e-04\n",
      "Epoch 130/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0014 - val_loss: 9.3961e-04\n",
      "Epoch 131/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0014 - val_loss: 8.8966e-04\n",
      "Epoch 132/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 9.3524e-04\n",
      "Epoch 133/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 9.3716e-04\n",
      "Epoch 134/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0014 - val_loss: 8.8316e-04\n",
      "Epoch 135/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0013 - val_loss: 9.2129e-04\n",
      "Epoch 136/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0014 - val_loss: 8.7456e-04\n",
      "Epoch 137/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0014 - val_loss: 9.0640e-04\n",
      "Epoch 138/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0013 - val_loss: 9.0215e-04\n",
      "Epoch 139/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0014 - val_loss: 8.8996e-04\n",
      "Epoch 140/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0013 - val_loss: 8.7461e-04\n",
      "Epoch 141/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0014 - val_loss: 9.0939e-04\n",
      "Epoch 142/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0014 - val_loss: 9.4570e-04\n",
      "Epoch 143/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0013 - val_loss: 8.8249e-04\n",
      "Epoch 144/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 145/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0014 - val_loss: 9.7918e-04\n",
      "Epoch 146/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0014 - val_loss: 8.8976e-04\n",
      "Epoch 147/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 9.2429e-04\n",
      "Epoch 148/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0014 - val_loss: 9.5527e-04\n",
      "Epoch 149/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 150/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 151/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0014 - val_loss: 8.7458e-04\n",
      "Epoch 152/400\n",
      "12234/12234 [==============================] - 0s 30us/sample - loss: 0.0014 - val_loss: 8.6850e-04\n",
      "Epoch 153/400\n",
      "12234/12234 [==============================] - 1s 51us/sample - loss: 0.0014 - val_loss: 9.3864e-04\n",
      "Epoch 154/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0013 - val_loss: 8.9849e-04\n",
      "Epoch 155/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 8.6290e-04\n",
      "Epoch 156/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 9.0173e-04\n",
      "Epoch 157/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0013 - val_loss: 8.8653e-04\n",
      "Epoch 158/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0014 - val_loss: 8.8868e-04\n",
      "Epoch 159/400\n",
      "12234/12234 [==============================] - 0s 24us/sample - loss: 0.0014 - val_loss: 9.6132e-04\n",
      "Epoch 160/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 8.5222e-04\n",
      "Epoch 161/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0013 - val_loss: 8.9748e-04\n",
      "Epoch 162/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0013 - val_loss: 8.6230e-04\n",
      "Epoch 163/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0013 - val_loss: 8.7370e-04\n",
      "Epoch 164/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0013 - val_loss: 8.6128e-04\n",
      "Epoch 165/400\n",
      "12234/12234 [==============================] - 1s 41us/sample - loss: 0.0013 - val_loss: 8.9878e-04\n",
      "Epoch 166/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 9.7438e-04\n",
      "Epoch 167/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0014 - val_loss: 8.4715e-04\n",
      "Epoch 168/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0014 - val_loss: 8.7642e-04\n",
      "Epoch 169/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0013 - val_loss: 8.7425e-04\n",
      "Epoch 170/400\n",
      "12234/12234 [==============================] - 1s 41us/sample - loss: 0.0013 - val_loss: 8.5480e-04\n",
      "Epoch 171/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0013 - val_loss: 9.1954e-04\n",
      "Epoch 172/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0013 - val_loss: 8.4822e-04\n",
      "Epoch 173/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0013 - val_loss: 8.7768e-04\n",
      "Epoch 174/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0013 - val_loss: 8.6127e-04\n",
      "Epoch 175/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0014 - val_loss: 9.2293e-04\n",
      "Epoch 176/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0013 - val_loss: 8.5702e-04\n",
      "Epoch 177/400\n",
      "12234/12234 [==============================] - 0s 35us/sample - loss: 0.0013 - val_loss: 9.6080e-04\n",
      "Epoch 178/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0014 - val_loss: 8.6618e-04\n",
      "Epoch 179/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0013 - val_loss: 9.6074e-04\n",
      "Epoch 180/400\n",
      "12234/12234 [==============================] - 0s 39us/sample - loss: 0.0013 - val_loss: 9.1898e-04\n",
      "Epoch 181/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.6071e-04\n",
      "Epoch 182/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 183/400\n",
      "12234/12234 [==============================] - 0s 36us/sample - loss: 0.0013 - val_loss: 9.8130e-04\n",
      "Epoch 184/400\n",
      "12234/12234 [==============================] - 0s 34us/sample - loss: 0.0014 - val_loss: 9.0910e-04\n",
      "Epoch 185/400\n",
      "12234/12234 [==============================] - 0s 26us/sample - loss: 0.0013 - val_loss: 9.2773e-04\n",
      "Epoch 186/400\n",
      "12234/12234 [==============================] - 0s 23us/sample - loss: 0.0013 - val_loss: 8.3206e-04\n",
      "Epoch 187/400\n",
      "12234/12234 [==============================] - 0s 37us/sample - loss: 0.0013 - val_loss: 8.4316e-04\n",
      "Epoch 188/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0013 - val_loss: 8.5757e-04\n",
      "Epoch 189/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.5811e-04\n",
      "Epoch 190/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.5083e-04\n",
      "Epoch 191/400\n",
      "12234/12234 [==============================] - 0s 38us/sample - loss: 0.0013 - val_loss: 8.4172e-04\n",
      "Epoch 192/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.6477e-04\n",
      "Epoch 193/400\n",
      "12234/12234 [==============================] - 1s 48us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 194/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0013 - val_loss: 8.6538e-04\n",
      "Epoch 195/400\n",
      "12234/12234 [==============================] - 1s 41us/sample - loss: 0.0013 - val_loss: 8.7284e-04\n",
      "Epoch 196/400\n",
      "12234/12234 [==============================] - 0s 31us/sample - loss: 0.0013 - val_loss: 8.2920e-04\n",
      "Epoch 197/400\n",
      "12234/12234 [==============================] - 1s 51us/sample - loss: 0.0013 - val_loss: 8.6397e-04\n",
      "Epoch 198/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0013 - val_loss: 8.1389e-04\n",
      "Epoch 199/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.4034e-04\n",
      "Epoch 200/400\n",
      "12234/12234 [==============================] - 1s 53us/sample - loss: 0.0013 - val_loss: 8.3994e-04\n",
      "Epoch 201/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0013 - val_loss: 8.4443e-04\n",
      "Epoch 202/400\n",
      "12234/12234 [==============================] - 0s 41us/sample - loss: 0.0013 - val_loss: 8.3627e-04\n",
      "Epoch 203/400\n",
      "12234/12234 [==============================] - 0s 33us/sample - loss: 0.0013 - val_loss: 8.3108e-04\n",
      "Epoch 204/400\n",
      "12234/12234 [==============================] - 1s 51us/sample - loss: 0.0013 - val_loss: 8.1901e-04\n",
      "Epoch 205/400\n",
      "12234/12234 [==============================] - 1s 49us/sample - loss: 0.0013 - val_loss: 8.5512e-04\n",
      "Epoch 206/400\n",
      "12234/12234 [==============================] - 1s 50us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 207/400\n",
      "12234/12234 [==============================] - 1s 53us/sample - loss: 0.0013 - val_loss: 8.2622e-04\n",
      "Epoch 208/400\n",
      "12234/12234 [==============================] - 0s 40us/sample - loss: 0.0013 - val_loss: 8.4730e-04\n",
      "Epoch 209/400\n",
      "12234/12234 [==============================] - 1s 47us/sample - loss: 0.0013 - val_loss: 8.7953e-04\n",
      "Epoch 210/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.3696e-04\n",
      "Epoch 211/400\n",
      "12234/12234 [==============================] - 1s 46us/sample - loss: 0.0013 - val_loss: 8.3434e-04\n",
      "Epoch 212/400\n",
      "12234/12234 [==============================] - 1s 44us/sample - loss: 0.0013 - val_loss: 8.1822e-04\n",
      "Epoch 213/400\n",
      "12234/12234 [==============================] - 1s 42us/sample - loss: 0.0013 - val_loss: 8.3271e-04\n",
      "Epoch 214/400\n",
      "12234/12234 [==============================] - 1s 45us/sample - loss: 0.0013 - val_loss: 8.2899e-04\n",
      "Epoch 215/400\n",
      "12234/12234 [==============================] - 0s 30us/sample - loss: 0.0014 - val_loss: 8.9981e-04\n",
      "Epoch 216/400\n",
      "12234/12234 [==============================] - 0s 32us/sample - loss: 0.0013 - val_loss: 8.2493e-04\n",
      "Epoch 217/400\n",
      "12234/12234 [==============================] - 0s 32us/sample - loss: 0.0013 - val_loss: 8.3168e-04\n",
      "Epoch 218/400\n",
      "12234/12234 [==============================] - 0s 30us/sample - loss: 0.0013 - val_loss: 8.8619e-04\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x=X_train, y=y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stop]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             multiple                  870       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             multiple                  1740      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             multiple                  6844      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             multiple                  3393      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             multiple                  420       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             multiple                  15        \n",
      "=================================================================\n",
      "Total params: 13,282\n",
      "Trainable params: 13,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model.history.history\n",
    "losses['loss'] = np.asarray(losses['loss'])\n",
    "losses['val_loss'] = np.asarray(losses['val_loss'])\n",
    "final_number_of_epochs = len(losses['loss'])\n",
    "min_loss = losses['loss'].min()\n",
    "mean_loss = losses['loss'].mean()\n",
    "final_loss = losses['loss'][-1]\n",
    "min_val_loss = losses['val_loss'].min()\n",
    "mean_val_loss = losses['val_loss'].mean()\n",
    "final_val_loss = losses['val_loss'][-1]\n",
    "\n",
    "def get_model_summary():\n",
    "    output = []\n",
    "    model.summary(print_fn=lambda line: output.append(line))\n",
    "    return str(output).strip('[]')\n",
    "\n",
    "summary = get_model_summary()\n",
    "\n",
    "record = {\n",
    "    'Epochs': final_number_of_epochs,\n",
    "    'Batch_Size': batch_size,\n",
    "    'Loss_Func': loss_param,\n",
    "    'Optimizer': optimizer_param,\n",
    "    'Early_Stop_Monitor': stop_monitor,\n",
    "    'Early_Stop_Patience': stop_patience,\n",
    "    'Min_Loss': min_loss,\n",
    "    'Mean_Loss': mean_loss,\n",
    "    'Final_Loss': final_loss,\n",
    "    'Min_Val_Loss': min_val_loss,\n",
    "    'Mean_Val_Loss': mean_val_loss,\n",
    "    'Final_Val_Loss': final_val_loss,\n",
    "    'Model': summary\n",
    "}\n",
    "\n",
    "new_data = pd.DataFrame(record, index=[0])\n",
    "\n",
    "if os.path.exists('../core/records/batting_results.csv'):\n",
    "    df_records = pd.read_csv('../core/records/batting_results.csv')\n",
    "    df_records = df_records.append(new_data)\n",
    "else:\n",
    "    df_records = pd.DataFrame(new_data)\n",
    "    \n",
    "df_records.to_csv('../core/records/batting_results.csv', index=False, float_format='%g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x148e5fdd0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = [pred for sublist in predictions for pred in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_player_ratings = dict(zip(X_test_keys, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_key = df['retroID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        aardd001\n",
       "1        aaroh101\n",
       "2        aarot101\n",
       "3        aased001\n",
       "4        abada001\n",
       "           ...   \n",
       "15288    zupcb001\n",
       "15289    zupof101\n",
       "15290    zuveg101\n",
       "15291    zuvep001\n",
       "15292    zycht001\n",
       "Name: retroID, Length: 15293, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(tensor.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15293"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11595928"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15293,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Batting'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15293, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [pred for sublist in results for pred in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df['Batting'] - results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x145c29890>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005629653826018003"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf2env': conda)",
   "language": "python",
   "name": "python37664bittf2envconda7a5d2b04ce96452f92a2890aed430c66"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
